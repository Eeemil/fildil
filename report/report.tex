% Standard document setting, is the most appropriate output for reports that
% are to be printed. When handing in electronically please remove the
% "twoside" option.
\documentclass[10pt, a4paper]{article}

\usepackage[T1]{fontenc}
\usepackage[UKenglish]{isodate}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{minted}

\usepackage{graphicx}
\usepackage{multicol}

% The following package allows us to define our own macros
% through "\LetLtxMacro\ourName\originalName"
\usepackage{letltxmacro}

% Adds vertical space between paragraphs, i.e. a clean linebreak
\usepackage{parskip}
\usepackage{verbatim}

% Math commands
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newtheorem{definition}{Definition}
\usepackage{float}
\usepackage{footmisc} % Use symbols instead of numbers for footnotes
\usepackage{csquotes}
\usepackage{hyperref}
\hypersetup{
  colorlinks = true, % Colours links instead of ugly boxes
    urlcolor = blue, % Colour for external hyperlinks
      linkcolor = blue, % Colour of internal links
        citecolor = red % Colour of citations
	}

% Used to get the last page of the document, used in our document headers
\usepackage{lastpage}

% Specify date format
\usepackage[yyyymmdd]{datetime}
\renewcommand\dateseparator{-} % Separate date tokens with a "-"

% Use fancy document headers
\usepackage{fancyhdr}

\usepackage{letltxmacro}
\usepackage{float}

% An environment for nice looking quotes
\makeatletter
\newenvironment{chapquote}[2][2em]
{\setlength{\@tempdima}{#1}%
  \def\chapquote@author{#2}%
    \parshape 1 \@tempdima \dimexpr0.5\textwidth-2\@tempdima\relax}
    {\par\normalfont\hfill\ \chapquote@author\hspace*{\@tempdima}\par}
    \makeatother

%
% BibLaTeX
%
% Great reference system
% Documentation:
% http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf
% ___________________________________________________________
\usepackage[style = ieee, urldate =comp, backend=biber]{biblatex}
\addbibresource{sources.bib}

\newcommand{\department}{Department of Computing Science}
\newcommand{\uni}{Ume\aa\ University}

\newcommand{\authors}{Emil Marklund (\texttt{eeemil@cs.umu.se})\\Timmy Olsson(\texttt{c12ton@cs.umu.se})}
  \newcommand{\documentTitle}{Project report -- Fildil}
  \title{\documentTitle}
  \author{\authors}
  \newcommand{\coursename}{Advanced distributed systems}
  \newcommand{\coursecode}{5DV121}
  \newcommand{\semester}{HT16}
  \newcommand{\credits}{7.5}
  \newcommand{\instructors}{P-O Ã–stberg (\texttt{p-o@cs.umu.se}), Adam Dahlgren (\texttt{dali@cs.umu.se})}
  \pagestyle{fancy}

\usepackage{color}
\usepackage{float}
\usepackage{fancyvrb}
\usepackage[scaled]{beramono}

\usepackage{listings}

% Code snippet syntax
\lstset{backgroundcolor=\color{GhostWhite}, basicstyle={\small\ttfamily},
  breakatwhitespace=false, breaklines=false, captionpos=b,
  commentstyle=\color{Green}, frame=single, keywordstyle=\color{Blue},
  language=C, % C has somewhat similar syntax to Rust
  morekeywords={fn, let, mut, unsafe, trait, as, macro, override, ref, type,
    virtual, box, in, mod, priv, typeof,
    where}, % Additional keywords used in Rust
  rulecolor=\color{LightSteelBlue}, showspaces=false, showtabs=false,
  showstringspaces=false, stringstyle=\color{FireBrick}, tabsize=4, float }
\renewcommand{\lstlistingname}{Code snippet}

% \BeforeBeginEnvironment{listings}{\par\noindent\begin{minipage}{\linewidth}}
%   \AfterEndEnvironment{listings}{\end{minipage}\par\addvspace{\topskip}}

\begin{document}

\raggedbottom

\date{}
\begin{titlepage}
  \maketitle

   \fancyfoot{}

  \thispagestyle{fancy}
    \headheight 35pt

  \lhead{\small \department \\
      \uni} % These two are also defined in config.sty

  \rhead{\small \today} %date



  \cfoot{\coursename\ (\coursecode), \credits\ hp -- \semester\\
      Supervisor(s): \instructors}

\end{titlepage}

% Header settings
\fancyhead[LE,RO]{\thepage(\pageref{LastPage})}
\fancyheadoffset[LE,RO]{12mm}
\fancyhead[LO,RE]{\coursename}
\fancyfoot[L,R,C]{}

\tableofcontents

\clearpage

\pagenumbering{arabic}

\setlength{\parindent}{0pt}

\section{Introduction}

This document is a project report for the development of \emph{Fildil}, a video
streaming application designed to be scalable by splitting load between everyone
interested in the stream in a peer to peer manner.

This section contains a number of subsections: in \autoref{sec:goals} you may
read more extensible about the problems Fildil is supposed to solve,
\autoref{sec:terminology} contains a definite guide to the terminology used
throughout this report and \autoref{sec:building-running} consists of
instructions on using the application.

\autoref{sec:design} presents the high-level design philosophies for building
Fildil, e.g. algorithms. In \autoref{sec:system}, the actual implementation is
discussed in greater detail. Finally, the performance of Fildil is evaluated in
\autoref{sec:results}. This document is ended with \autoref{sec:discussion}
which presents our conclusions, improvements and experiences from the project.

\subsection{Terminology}
\label{sec:terminology}

The following terminology is used throughout the report.

\begin{description}
\item[Video source] the source used to generate the streaming data. For example,
  \texttt{FFmpeg} reading a video file could be a video source.
\item[Chunk] A data packet containing a small part of the streamed
  content, with metadata.
\item[Node] Any participant of the \emph{streaming network}: downloading and/or
  uploading \emph{chunks} of the stream
\item[Streaming network] All \emph{nodes} participating in generating and
  sharing chunks.
\item[Primary node] \emph{Node} reading directly from the \emph{video source},
  \emph{generating} chunks for the \emph{streaming network}.
\item[Peer node] \emph{Node} reading from the \emph{streaming network}, sharing
  \emph{chunks} with other nodes. Differs from \emph{primary node} in that it
  does not generate any chunks on its own, it merely downloads chunks and
  uploads them to other \emph{peer nodes} on request.
\end{description}

\subsection{Goals}
\label{sec:goals}

The application has been designed with the following goals in mind:

\begin{description}
\item[Robustness] The system should be able to \emph{automatically} handle
  increase of nodes(i.e computers collaborating on providing the service).
\item[Extensibility] To the extent it is possible, new features should be able
  to be added to Fildil without having to redesign earlier components.
\item[Load balancing/consistent QoS] Fildil should be able to adapt to spikes in
  load in order to provide a consistent Quality of Service.
\item [Multiple streamer and viewer clients] The system should support multiple
  streaming clients as well as multiple viewer clients.
\end{description}

In Fildil, every node joining the streaming network polls one (or more) existing
nodes to get a list of the existing node's peers. In that manner, a joining node
may recursively poll peers within the streaming network to build knowledge of
the streaming network. Simultaneously, the polled peers gets knowledge of a
joining node. 

This automatic organization scheme has been implemented in accordance with the
\emph{robustness}-goal, and the \emph{multiple streamer and viewer client}
goal.

Google Protocol Buffers has been used for designing the service with
GRPC. However, with the existing protocol buffer and the operations designed for
the service, it would be possible to implement Fildil in other languages without
too much effort. This is in accordance with the \emph{extensibility}-goal.

Fildil splits the video source into chunks, and the complete streaming network
shares the responsibility of distributing the chunks. This is thought to fulfill
the \emph{load balancing/consistent QoS} goal.

\subsection{Building \& running}
\label{sec:building-running}

\subsubsection{Prerequisites}

The following prerequisites exists for building and running Fildil:

\begin{description}
\item[Java 1.8] Fildil is written in Java and makes use of features available
  only in Java 8 or newer. Throughout development, \texttt{Java Runtime
    Environment 1.8.0\_25-b17} has been used.
\item[Maven] In order to build Fildil, Maven is required. \texttt{Maven 3.0.5}
  has been used during development.
\item[FFmpeg] Fildil uses FFmpeg for reading a video source. \texttt{FFmpeg
    3.2-2~bpo8+2, built with gcc 4.9.2 (Debian 4.9.2-10)} has been used
  during testing. \textbf{FFmpeg is only a prerequisite for primary nodes}.
\item[POSIX-compliant OS] Pipes are used for communication between Fildil and
  other programs (such as \emph{VLC} and \emph{FFmpeg}). Testing has been
  performed on \texttt{Debian 3.16.36-1+deb8u2 (Linux 3.16.0-4-amd64)}.
\item[VLC media player] In order to watch the streamed content, a media player
  able to manage streaming needs to be used. \texttt{VLC media player 2.2.4
    (revision 2.2.3-37-g888b7e89)} has been used during testing.
\end{description}

\subsubsection{Compiling Fildil}

mvn package
%todo: more information

\subsubsection{Running a primary node}

Run,
%todo: add instructions

\subsubsection{Running a peer node}

Forrest, run!
%todo: add instructions - remember flag information


\section{Design: decentralized peer to peer streaming}
\label{sec:design}

In this section, overall design of the system is explained.
 %todo: write better introduction

\subsection{Splitting and sharing chunks}

The core mechanic of Fildil is splitting the video stream into chunks
and letting the nodes in the streaming network share the chunks among
themselves. 

The primary node may for example split 10 seconds of a video stream
into three chunks such that the peer nodes \emph{1}, \emph{2} and
\emph{3} receives the chunks \emph{A}, \emph{B} and \emph{C}. The peer
nodes may then exchange the chunks among themselves, \emph{1}
sends \emph{A} to \emph{2} and \emph{3} while \emph{2} sends \emph{B}
to \emph{1} and \emph{3}, and finally \emph{3} sends \emph{C} to
\emph{1} and \emph{2}.

This is similar to the \emph{torrent} protocol. The purpose of this
technique is to provide load balancing, see \autoref{sec:goals}.

%todo: Add a descriptive torrenting figure

\subsection{Service definition}
\label{sec:protobuf}

Each node in Fildil has a high level API as a webservice. The service
is defined using Google's Protocol Buffer (see
\autoref{fig:protobuf}), with automatically generated gRPC
bindings. The service can perform the following operations:

\begin{description}
\item[poll] A node, \textbf{A}, may send a poll request to another
  node, \textbf{B}. \textbf{A} sends along information it knows about
  the streaming network, and \textbf{B} replies with information it
  knows about the streaming network. The poll operation is used for
  nodes to be able to self-organize within the network, e.g. for
  getting knowledge of available nodes to download from when joining a
  streaming network.
\item[requestChunk] This is the core operation for downloading chunks
  of the stream. It simply requests a chunk with a specific ID, and
  gets a proper chunk back if it exists.
\end{description}

The service definition is purposely left quite primitive. We have
aimed Fildil to be extensible (see \autoref{sec:goals}) and we have
therefore not added functionality until we absolutely needed it: it is
often possible to add fields or operation to a protocol definition
without big problems once the service is stable and in use. However,
removing and/or changing existing fields or operations breaks
compatibility with services running the old version.

\begin{figure}[H]
\begin{minted}[frame=single]{protobuf}
syntax="proto3";
option java_package ="se.umu.cs.ads.fildil.proto.autogen";
option java_multiple_files = true;
option java_outer_classname = "Protocol";

service Streamer {
    //Request a specific chunk
    rpc requestChunk(ChunkRequest) returns (Chunk){}
    //Exchange peer information
    rpc poll(PeerInfo) returns (PeerInfo){}
}

message Chunk {
    int32 id = 1;
    bytes buf = 2;
}

message PeerInfo {
    int32 highestChunk= 1;
    string uuid = 2;
    string address = 3;
    //<uuid, address:port>
    map<string, string> peers = 4;
}

message ChunkRequest {
    int32 id = 1;
}

message ReceiveChunkReply {}
\end{minted}
\caption{Protocol buffer definition used for defining the service}
\label{fig:protobuf}
\end{figure}

\subsection{Node discovery}
\label{sec:node-discovery}

As mentioned in \autoref{sec:protobuf}, nodes may poll each others to
gain information about the streaming network. For node discovery, a
node \textbf{A} may poll a node \textbf{B} for \textbf{A} to gain
information of the peers of \textbf{B}.

Peers are added in a greedy fashion, where a node adds a peer as soon
as the existence of the peer becomes known to the peer, see Algorithm
\autoref{alg:peerextract} and Algorithm \autoref{alg:onpoll}. For
example, when joining, a node needs to get information about at least
one other node in the streaming network. The joining node then asks
for the peers of the existing node, and recursively asks the peers for
their peers and so on.

This mechanism has been added to ensure the goals of robustness and
managing multiple clients, see \autoref{sec:goals}.

\begin{algorithm}
  \caption{Greedy peer extraction scheme}
  \label{alg:peerextract}
  \begin{algorithmic}[1]
    \Procedure{connect}{$u$}\Comment{$u$ - uri to a node in the streaming network}
    \State $n \gets$poll($u$)\Comment{Gets information about the node $n$}
    \If{connection successful}
    \State addPeer($n$)
    \State $l \gets$getPeers($n$)
    \ForAll{$p$ in $l$}
    \If{$p$ is unknown to the current node}
    \State connect($a$)
    \EndIf
    \EndFor
    \Else
    \State \Return
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Performed when being polled by a node $n$}
  \label{alg:onpoll}
  \begin{algorithmic}[1]
    \Procedure{onPoll}{$n$}\Comment{$n$ - information about the polling node}
    \If{$n$ is a unknown to the current node}
    \State $u\gets$URI($n$)
    \State connect($u$)
    \EndIf
    \State \Return the current nodes information
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\section{System architecture}
\label{sec:system}

It was built by using code
%Todo: expand on this

\subsection{Managing errors}

\subsubsection{Node crash}
%Todo: Expand on this
If a node crashes, all information about that node should be discarded from all
other nodes. This is easy enough if a node that crashes never comes
back. However, problems can occur if the following situation comes up:

Say that Node A has highest chunk 1000 and address ``1.2.3.4:5678''. Node A
crashes and comes back up instantly, but losing all downloaded chunks in the
process. The node will then have a new highest chunk value of -1. However, this
can impair the streaming logic of other nodes assuming that Node A has highest
chunk value of 1000.

This is solved by assigning a UUID to each node on startup. Nodes communicating
with Node A will see that Node A has changed UUID, and will then dismiss all old
information about Node A.

\section{Results}
\label{sec:results}

The results are in
%Todo: add the results

\subsection{Benchmarks}

Fildil scores over 9000
%Todo: remove the lies, add the truths

\section{Discussion}
\label{sec:discussion}

\subsection{Project experiences}

%Todo: working by distance - experiences? What did we do good? What did we do bad?



\subsection{Improvements}

There are some ideas that could provide a significant improvement of Fildil, but
has been left out for not being viable within the project scope or not
sufficiently significant in regard to the project requirements.

\subsubsection{Data storage}
\label{sec:storage-improvements}

In the current implementation of Fildil, the complete stream is downloaded from
the beginning of the stream, to the end. Also, it is kept in memory for all node
types. This may be impractical for long-running streams, where the stream could
be very large in size:

\begin{enumerate}
\item Keeping lots of video streaming data in memory is very costly with the
  computer hardware of today. There is a need of caching the data for any node
  storing large parts of the stream. Caching has not been implemented in Fildil,
  instead, we have only used streams that have been able to be kept in memory on
  our testing equipment.
\item Another way to deal with the large data size in a peer to peer network is
  to split the streaming content storage on the nodes such that no node needs to
  keep a large part by itself. This mechanism has been left out due to time
  constraints. %TODO: has it still been left out?
\item Downloading the stream from beginning to end is probably not a realistic
  behavior for live streams. A more realistic behavior is to start the
  downloading at the most recent point of the stream (as close to ``live'' as
  possible). This would reduce the data size needed. This has been left out in
  Fildil, as we have argued that this behavior would make benchmarking harder
  and add complexity to our test environment, while only adding the benefit of
  needing to store less data in memory.
\end{enumerate}

\subsubsection{Investigate video streaming encodings}

Throughout the project, \emph{FFMpeg} has been used to convert a video
source to raw bytes in some kind of streaming media encoding. Fildil
is agnostic to what kind of data is supplied by FFMpeg. However,
FFMPeg could probably use a more suitable streaming codec.

Throughout the project, FFMpeg has been set to use any streaming
encoding. These settings can probably be fine-tuned to our application
though, e.g. by generating a stream in chunks of the same size as
Fildil internally uses, for improving the QoS.

\subsubsection{Scalable peer management}

As seen in \autoref{sec:node-discovery}, peers are greedily added to a
node whenever a node gains knowledge of a new node. The information
stored about each peer is not much: an integer for the highest chunk
number, 128-bit UUID:s and a URI string. This might not be suitable
for a stream shared by millions of users, especially if every peer is
to be probed from time to time in order to determine suitable peers to
download from.

We can probably keep record of only a fraction of the total number of
nodes in the streaming network and still keep the network stable.

One method of doing that while still providing a good quality of
service for all, is to only keep a list of ``good peers''. This list
should perhaps be a logarithmic function of an estimate of the total
number of peers (determined statistically by crawling through the
streaming network).

A drawback of the proposed scheme above would perhaps be that nodes
with bad connection would have a hard time getting suitable peers if
nodes only should add peers with good performance. However, even
though it is unlikely that the bad node will be added as a peer by
``good nodes'', the bad nodes may still add the good nodes as peers
and pull chunks from them even though the good nodes wont add the bad
peer back.

Testing these kinds of improvements has however been left out during
this project, as we have not had access to a test environment suitable
of running Fildil where amount of peers would become a scalability
issue.

\newpage

% \printbibliography
%\begin{thebibliography}{99}

%\end{thebibliography}

\end{document}

